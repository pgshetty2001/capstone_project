{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpATYJjld5r5r8llhPKloh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgshetty2001/capstone_project/blob/main/CloudXLab_Capstone_Project_withUSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MfjXYHDnVU8r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6ptjks-XbUl",
        "outputId": "9caf414e-ae0a-417f-9210-afbfe6079ff7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/MyDrive/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QZ2ncuYXv2l",
        "outputId": "49d2df16-2717-47b8-9ceb-0800b5a37d94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon_review_small.txt  df_test.csv  df_train.csv  raw  train\tuser_email_prefs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path='/content/gdrive/MyDrive/data/amazon_review_small.txt'\n",
        "def read_data():\n",
        "    # Define a custom dialect to handle quotes and commas\n",
        "    csv.register_dialect('myDialect', delimiter = ',', quotechar = '\"', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
        "    with open(file_path, 'r') as file:\n",
        "        reader = csv.reader(file, dialect='myDialect')\n",
        "        data = list(reader)\n",
        "    # Create DataFrame and assign column names\n",
        "    df_reviews = pd.DataFrame(data[1:], columns=[\"star_rating\", \"review_headline\", \"review_body\"])  # Assuming first row is header\n",
        "    return df_reviews\n",
        "df_reviews = read_data()"
      ],
      "metadata": {
        "id": "WD19OfpnXxhY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## FEATURE CONSTRUCTION CODE HERE ##\n",
        "from sklearn.model_selection import train_test_split  # Import the function\n",
        "\n",
        "X = df_reviews['review_body']\n",
        "y = df_reviews['star_rating']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)"
      ],
      "metadata": {
        "id": "acjzY6JLX6EA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "embed_model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "def embed(input):\n",
        "  return model(input)\n",
        "\n",
        "def embed(input):\n",
        "  return embed_model(input).numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlySRl6kYKUm",
        "outputId": "eedfc7b8-61c2-42a1-e1c0-343c582c4df9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiny Dataset (replacing with our actual data loading)\n",
        "X_tiny = X[:10000]\n",
        "y_tiny = y[:10000]\n",
        "\n",
        "# Embed the text data using Universal Sentence Encoder\n",
        "X_tiny_embed = embed_model(X_tiny.tolist())\n",
        "\n",
        "#print(\"Tiny Dataset (X_tiny_vec):\", X_tiny_vec)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(np.array(X_tiny_embed))\n",
        "\n",
        "# Import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression # Import the class\n",
        "\n",
        "# Import accuracy_score\n",
        "from sklearn.metrics import accuracy_score # Import the function for calculating accuracy\n",
        "\n",
        "\n",
        "# Simple Logistic Regression\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_scaled, y_tiny)\n",
        "\n",
        "# Prediction and Evaluation\n",
        "y_pred_tiny = model.predict(X_scaled)\n",
        "accuracy_tiny = accuracy_score(y_tiny, y_pred_tiny)\n",
        "print(\"Tiny Dataset Accuracy:\", accuracy_tiny)\n",
        "\n",
        "# Printing everything\n",
        "#print(\"Tiny Dataset (X):\", X_tiny)\n",
        "#print(\"Tiny Dataset Labels (y):\", y_tiny)\n",
        "#print(\"TF-IDF Vectors:\", X_tiny_vec.toarray()) # Convert to dense for easy viewing\n",
        "#print(\"Predicted Labels:\", y_pred_tiny)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hblwfchYk1g",
        "outputId": "95c16abc-da68-4add-daa5-88a651af6cf4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiny Dataset Accuracy: 0.5469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PUdY976Fa6rC",
        "outputId": "db37c2ad-eb62-4276-a564-3b0e9e7a67d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mord\n",
            "  Downloading mord-0.7.tar.gz (8.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mord\n",
            "  Building wheel for mord (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mord: filename=mord-0.7-py3-none-any.whl size=9886 sha256=51cace5a1f6c62a37f3ff5c599f32868f13d0eb6da9be9e796189ea23f4d252e\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/00/19/3cea86fbfc737ec4acb515cd94497dcc33f943fa157548b96c\n",
            "Successfully built mord\n",
            "Installing collected packages: mord\n",
            "Successfully installed mord-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mord import LogisticIT\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "\n",
        "# Tiny Dataset (replacing with our actual data loading)\n",
        "X_tiny = X[:10000]\n",
        "y_tiny = y[:10000]\n",
        "\n",
        "# Convert y_tiny to numeric, forcing non-convertibles to NaN\n",
        "y_tiny = pd.to_numeric(y_tiny, errors='coerce')\n",
        "\n",
        "# Remove rows with NaN values in y_tiny\n",
        "X_tiny = X_tiny[y_tiny.notna()]\n",
        "y_tiny = y_tiny[y_tiny.notna()].astype(int)  # Convert to integers after removing NaNs\n",
        "\n",
        "# Embed the text data using Universal Sentence Encoder\n",
        "X_tiny_embed = embed_model(X_tiny.tolist())\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(np.array(X_tiny_embed))\n",
        "\n",
        "# Simple Logistic Regression\n",
        "model = LogisticIT()\n",
        "model.fit(X_scaled, y_tiny)\n",
        "\n",
        "# Prediction and Evaluation\n",
        "y_pred_tiny = model.predict(X_scaled)\n",
        "accuracy_tiny = accuracy_score(y_tiny, y_pred_tiny)\n",
        "print(\"Tiny Dataset Accuracy:\", accuracy_tiny)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse_tiny = mean_squared_error(y_tiny, y_pred_tiny)\n",
        "print(\"Tiny Dataset Mean Squared Error:\", mse_tiny)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae_tiny = mean_absolute_error(y_tiny, y_pred_tiny)  # Use MAE instead of MSE\n",
        "print(\"Tiny Dataset Mean Absolute Error:\", mae_tiny)\n",
        "\n",
        "# Printing everything\n",
        "#print(\"Tiny Dataset (X):\", X_tiny)\n",
        "#print(\"Tiny Dataset Labels (y):\", y_tiny)\n",
        "#print(\"TF-IDF Vectors:\", X_tiny_vec.toarray()) # Convert to dense for easy viewing\n",
        "#print(\"Predicted Labels:\", y_pred_tiny)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcq0C-iGa-ru",
        "outputId": "4baff420-8ade-4c58-9959-e5091bf4496c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiny Dataset Accuracy: 0.4308\n",
            "Tiny Dataset Mean Squared Error: 1.2894\n",
            "Tiny Dataset Mean Absolute Error: 0.7798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mord import LogisticIT, LogisticAT, LAD\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "from sklearn.base import ClassifierMixin, RegressorMixin  # Import ClassifierMixin\n",
        "\n",
        "\n",
        "# Tiny Dataset (replacing with our actual data loading)\n",
        "X_tiny = X[:10000]\n",
        "y_tiny = y[:10000]\n",
        "\n",
        "# Convert y_tiny to numeric, forcing non-convertibles to NaN\n",
        "y_tiny = pd.to_numeric(y_tiny, errors='coerce')\n",
        "\n",
        "# Remove rows with NaN values in y_tiny\n",
        "X_tiny = X_tiny[y_tiny.notna()]\n",
        "y_tiny = y_tiny[y_tiny.notna()].astype(int)  # Convert to integers after removing NaNs\n",
        "\n",
        "# Embed the text data using Universal Sentence Encoder\n",
        "X_tiny_embed = embed_function(X_tiny.tolist())\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(np.array(X_tiny_embed))\n",
        "\n",
        "class LogisticITClassifier(LogisticIT, ClassifierMixin):\n",
        "    pass\n",
        "\n",
        "class LogisticATClassifier(LogisticAT, ClassifierMixin):\n",
        "    pass\n",
        "\n",
        "# Define individual models\n",
        "model1 = LogisticITClassifier()\n",
        "model2 = LogisticATClassifier()\n",
        "\n",
        "# Create a voting ensemble\n",
        "ensemble_model = VotingClassifier(estimators=[\n",
        "    ('logit', model1), ('logat', model2)],\n",
        "    voting='soft')  # 'hard' voting for majority class prediction\n",
        "\n",
        "# Fit the ensemble model\n",
        "ensemble_model.fit(X_scaled, y_tiny)\n",
        "\n",
        "# Prediction and Evaluation\n",
        "y_pred_tiny = ensemble_model.predict(X_scaled)\n",
        "accuracy_tiny = accuracy_score(y_tiny, y_pred_tiny)\n",
        "print(\"Tiny Dataset Accuracy (Ensemble):\", accuracy_tiny)\n",
        "\n",
        "mae_tiny = mean_absolute_error(y_tiny, y_pred_tiny)\n",
        "print(\"Tiny Dataset Mean Absolute Error (Ensemble):\", mae_tiny)\n",
        "\n",
        "# Restore the original 'embed' function if needed\n",
        "def embed_function(input):\n",
        "  return model(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s57a--KCkTj2",
        "outputId": "a504d513-ba27-42ad-d47f-18851401c15a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiny Dataset Accuracy (Ensemble): 0.377\n",
            "Tiny Dataset Mean Absolute Error (Ensemble): 1.0622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "\n",
        "# Data Preparation\n",
        "# Tiny Dataset (replacing with our actual data loading)\n",
        "X_tiny = X[:10000]\n",
        "y_tiny = y[:10000]\n",
        "\n",
        "# Convert y_tiny to numeric, forcing non-convertibles to NaN\n",
        "y_tiny = pd.to_numeric(y_tiny, errors='coerce')\n",
        "\n",
        "# Remove rows with NaN values in y_tiny\n",
        "X_tiny = X_tiny[y_tiny.notna()]\n",
        "y_tiny = y_tiny[y_tiny.notna()].astype(int)  # Convert to integers after removing NaNs\n",
        "\n",
        "# Embed the text data using Universal Sentence Encoder\n",
        "X_tiny_embed = embed(X_tiny.tolist())\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(np.array(X_tiny_embed))\n",
        "\n",
        "# Determine the input dimension from the shape of X_scaled\n",
        "input_dim = X_scaled.shape[1]\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=input_dim))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# One-hot encode labels\n",
        "y_tiny_onehot = tf.keras.utils.to_categorical(y_tiny - 1, num_classes=5)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_scaled, y_tiny_onehot, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Prediction and Evaluation\n",
        "y_pred_probs = model.predict(X_scaled)  # Get predicted probabilities\n",
        "y_pred_tiny = np.argmax(y_pred_probs, axis=1) + 1  # Convert probabilities to class labels (starting from 1)\n",
        "\n",
        "accuracy_tiny = accuracy_score(y_tiny, y_pred_tiny)\n",
        "print(\"Tiny Dataset Accuracy :\", accuracy_tiny)\n",
        "\n",
        "mae_tiny = mean_absolute_error(y_tiny, y_pred_tiny)\n",
        "print(\"Tiny Dataset Mean Absolute Error :\", mae_tiny)\n",
        "\n",
        "# Restore the original 'embed' function if needed\n",
        "def embed(input):\n",
        "  return model(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCjh2j0oGGiO",
        "outputId": "4cdd16df-a722-4db9-b6c4-714b397f7c8a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3083 - loss: 1.6544 - val_accuracy: 0.4190 - val_loss: 1.2997\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4635 - loss: 1.2368 - val_accuracy: 0.4325 - val_loss: 1.2670\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5088 - loss: 1.1510 - val_accuracy: 0.4245 - val_loss: 1.2876\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5479 - loss: 1.0733 - val_accuracy: 0.4280 - val_loss: 1.2860\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5580 - loss: 1.0390 - val_accuracy: 0.4285 - val_loss: 1.2971\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5997 - loss: 0.9844 - val_accuracy: 0.4305 - val_loss: 1.3178\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6045 - loss: 0.9492 - val_accuracy: 0.4165 - val_loss: 1.3402\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6355 - loss: 0.8994 - val_accuracy: 0.4180 - val_loss: 1.3806\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.8605 - val_accuracy: 0.4110 - val_loss: 1.4230\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6640 - loss: 0.8322 - val_accuracy: 0.4090 - val_loss: 1.4055\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6928 - loss: 0.7728 - val_accuracy: 0.4030 - val_loss: 1.4482\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6896 - loss: 0.7616 - val_accuracy: 0.4115 - val_loss: 1.4925\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7032 - loss: 0.7223 - val_accuracy: 0.4075 - val_loss: 1.5011\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7108 - loss: 0.7090 - val_accuracy: 0.4165 - val_loss: 1.5221\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.6695 - val_accuracy: 0.4135 - val_loss: 1.5885\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 0.6291 - val_accuracy: 0.3995 - val_loss: 1.5971\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7585 - loss: 0.6231 - val_accuracy: 0.4095 - val_loss: 1.6211\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7654 - loss: 0.5965 - val_accuracy: 0.4055 - val_loss: 1.6745\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7724 - loss: 0.5918 - val_accuracy: 0.4085 - val_loss: 1.7375\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.5822 - val_accuracy: 0.4050 - val_loss: 1.7402\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7794 - loss: 0.5636 - val_accuracy: 0.4140 - val_loss: 1.7475\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.5612 - val_accuracy: 0.4090 - val_loss: 1.7799\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.5231 - val_accuracy: 0.3960 - val_loss: 1.7509\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8034 - loss: 0.5138 - val_accuracy: 0.4030 - val_loss: 1.8047\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.5044 - val_accuracy: 0.3920 - val_loss: 1.8661\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8115 - loss: 0.4906 - val_accuracy: 0.3880 - val_loss: 1.8711\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.4767 - val_accuracy: 0.4045 - val_loss: 1.8624\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.4837 - val_accuracy: 0.3965 - val_loss: 1.8875\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.4610 - val_accuracy: 0.4000 - val_loss: 1.9446\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.4491 - val_accuracy: 0.4030 - val_loss: 1.9692\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.4391 - val_accuracy: 0.3950 - val_loss: 1.9811\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.4301 - val_accuracy: 0.4010 - val_loss: 1.9594\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.4482 - val_accuracy: 0.3950 - val_loss: 2.0088\n",
            "Epoch 34/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.4359 - val_accuracy: 0.3940 - val_loss: 2.0333\n",
            "Epoch 35/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.4221 - val_accuracy: 0.3990 - val_loss: 2.0088\n",
            "Epoch 36/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 0.3911 - val_accuracy: 0.4055 - val_loss: 2.0734\n",
            "Epoch 37/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.3960 - val_accuracy: 0.4060 - val_loss: 2.0625\n",
            "Epoch 38/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8535 - loss: 0.3935 - val_accuracy: 0.4050 - val_loss: 2.1055\n",
            "Epoch 39/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.3956 - val_accuracy: 0.4025 - val_loss: 2.0683\n",
            "Epoch 40/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3635 - val_accuracy: 0.3975 - val_loss: 2.1822\n",
            "Epoch 41/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8577 - loss: 0.3721 - val_accuracy: 0.3985 - val_loss: 2.1921\n",
            "Epoch 42/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3785 - val_accuracy: 0.3920 - val_loss: 2.1518\n",
            "Epoch 43/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.3934 - val_accuracy: 0.3920 - val_loss: 2.1998\n",
            "Epoch 44/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3802 - val_accuracy: 0.4040 - val_loss: 2.2278\n",
            "Epoch 45/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8670 - loss: 0.3512 - val_accuracy: 0.4050 - val_loss: 2.1951\n",
            "Epoch 46/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3587 - val_accuracy: 0.4040 - val_loss: 2.1834\n",
            "Epoch 47/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.3503 - val_accuracy: 0.3920 - val_loss: 2.1850\n",
            "Epoch 48/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8739 - loss: 0.3500 - val_accuracy: 0.3965 - val_loss: 2.2208\n",
            "Epoch 49/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8766 - loss: 0.3345 - val_accuracy: 0.4055 - val_loss: 2.2916\n",
            "Epoch 50/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8696 - loss: 0.3515 - val_accuracy: 0.4025 - val_loss: 2.3111\n",
            "Epoch 51/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8751 - loss: 0.3284 - val_accuracy: 0.3965 - val_loss: 2.3915\n",
            "Epoch 52/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.3068 - val_accuracy: 0.3995 - val_loss: 2.3426\n",
            "Epoch 53/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.3344 - val_accuracy: 0.3985 - val_loss: 2.3843\n",
            "Epoch 54/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.3378 - val_accuracy: 0.3960 - val_loss: 2.4092\n",
            "Epoch 55/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.3174 - val_accuracy: 0.4060 - val_loss: 2.3935\n",
            "Epoch 56/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2984 - val_accuracy: 0.4035 - val_loss: 2.4188\n",
            "Epoch 57/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8878 - loss: 0.3008 - val_accuracy: 0.4010 - val_loss: 2.4599\n",
            "Epoch 58/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.2929 - val_accuracy: 0.4030 - val_loss: 2.4021\n",
            "Epoch 59/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.3272 - val_accuracy: 0.3915 - val_loss: 2.5493\n",
            "Epoch 60/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8773 - loss: 0.3163 - val_accuracy: 0.3985 - val_loss: 2.4463\n",
            "Epoch 61/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8846 - loss: 0.3086 - val_accuracy: 0.3955 - val_loss: 2.4914\n",
            "Epoch 62/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8985 - loss: 0.2704 - val_accuracy: 0.3930 - val_loss: 2.6078\n",
            "Epoch 63/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2853 - val_accuracy: 0.3935 - val_loss: 2.5528\n",
            "Epoch 64/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.3060 - val_accuracy: 0.4040 - val_loss: 2.5154\n",
            "Epoch 65/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.2708 - val_accuracy: 0.4060 - val_loss: 2.6007\n",
            "Epoch 66/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.2871 - val_accuracy: 0.4005 - val_loss: 2.5002\n",
            "Epoch 67/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.2684 - val_accuracy: 0.4095 - val_loss: 2.6176\n",
            "Epoch 68/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.2581 - val_accuracy: 0.3880 - val_loss: 2.6290\n",
            "Epoch 69/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2765 - val_accuracy: 0.3965 - val_loss: 2.6368\n",
            "Epoch 70/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9025 - loss: 0.2852 - val_accuracy: 0.3905 - val_loss: 2.5369\n",
            "Epoch 71/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9053 - loss: 0.2476 - val_accuracy: 0.3890 - val_loss: 2.6208\n",
            "Epoch 72/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8996 - loss: 0.2758 - val_accuracy: 0.4095 - val_loss: 2.5081\n",
            "Epoch 73/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2692 - val_accuracy: 0.4065 - val_loss: 2.5557\n",
            "Epoch 74/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.2558 - val_accuracy: 0.3985 - val_loss: 2.6266\n",
            "Epoch 75/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9130 - loss: 0.2477 - val_accuracy: 0.4190 - val_loss: 2.6418\n",
            "Epoch 76/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9025 - loss: 0.2767 - val_accuracy: 0.4105 - val_loss: 2.5171\n",
            "Epoch 77/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2517 - val_accuracy: 0.4150 - val_loss: 2.6254\n",
            "Epoch 78/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2560 - val_accuracy: 0.4060 - val_loss: 2.6703\n",
            "Epoch 79/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.2440 - val_accuracy: 0.4130 - val_loss: 2.6540\n",
            "Epoch 80/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9127 - loss: 0.2324 - val_accuracy: 0.4025 - val_loss: 2.7511\n",
            "Epoch 81/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 0.2599 - val_accuracy: 0.4005 - val_loss: 2.7152\n",
            "Epoch 82/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.2400 - val_accuracy: 0.3875 - val_loss: 2.6952\n",
            "Epoch 83/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9169 - loss: 0.2381 - val_accuracy: 0.3910 - val_loss: 2.7679\n",
            "Epoch 84/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.2310 - val_accuracy: 0.3970 - val_loss: 2.7917\n",
            "Epoch 85/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9125 - loss: 0.2400 - val_accuracy: 0.3850 - val_loss: 2.8106\n",
            "Epoch 86/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2391 - val_accuracy: 0.3885 - val_loss: 2.6575\n",
            "Epoch 87/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9200 - loss: 0.2408 - val_accuracy: 0.3920 - val_loss: 2.8152\n",
            "Epoch 88/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2379 - val_accuracy: 0.4020 - val_loss: 2.7309\n",
            "Epoch 89/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9144 - loss: 0.2251 - val_accuracy: 0.3990 - val_loss: 2.7994\n",
            "Epoch 90/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2221 - val_accuracy: 0.3970 - val_loss: 2.8308\n",
            "Epoch 91/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2509 - val_accuracy: 0.4000 - val_loss: 2.7986\n",
            "Epoch 92/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2227 - val_accuracy: 0.3970 - val_loss: 2.8703\n",
            "Epoch 93/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.2083 - val_accuracy: 0.4010 - val_loss: 2.8329\n",
            "Epoch 94/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9257 - loss: 0.2117 - val_accuracy: 0.4040 - val_loss: 2.8119\n",
            "Epoch 95/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.2202 - val_accuracy: 0.3980 - val_loss: 2.9071\n",
            "Epoch 96/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.2257 - val_accuracy: 0.3965 - val_loss: 2.9094\n",
            "Epoch 97/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2103 - val_accuracy: 0.3910 - val_loss: 2.9089\n",
            "Epoch 98/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2123 - val_accuracy: 0.3895 - val_loss: 2.9664\n",
            "Epoch 99/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.2093 - val_accuracy: 0.4025 - val_loss: 2.8980\n",
            "Epoch 100/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1932 - val_accuracy: 0.4030 - val_loss: 2.9874\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Tiny Dataset Accuracy : 0.8803\n",
            "Tiny Dataset Mean Absolute Error : 0.1747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "\n",
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "embed_model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "def embed(input):\n",
        "  return embed_model(input)\n",
        "\n",
        "\n",
        "# Data Preparation\n",
        "# Medium Dataset (replacing with our actual data loading)\n",
        "X_med = X[:50000]\n",
        "y_med = y[:50000]\n",
        "\n",
        "# Convert y_tiny to numeric, forcing non-convertibles to NaN\n",
        "y_med = pd.to_numeric(y_med, errors='coerce')\n",
        "\n",
        "# Remove rows with NaN values in y_tiny\n",
        "X_med = X_med[y_med.notna()]\n",
        "y_med = y_med[y_med.notna()].astype(int)  # Convert to integers after removing NaNs\n",
        "\n",
        "# Embed the text data using Universal Sentence Encoder\n",
        "X_med_embed = embed(X_med.tolist())\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(np.array(X_med_embed))\n",
        "\n",
        "# Determine the input dimension from the shape of X_scaled\n",
        "input_dim = X_scaled.shape[1]\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=input_dim))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# One-hot encode labels\n",
        "y_med_onehot = tf.keras.utils.to_categorical(y_med - 1, num_classes=5)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_scaled, y_med_onehot, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Prediction and Evaluation\n",
        "y_pred_probs = model.predict(X_scaled)  # Get predicted probabilities\n",
        "y_pred_med = np.argmax(y_pred_probs, axis=1) + 1  # Convert probabilities to class labels (starting from 1)\n",
        "\n",
        "accuracy_med = accuracy_score(y_med, y_pred_med)\n",
        "print(\"Tiny Dataset Accuracy :\", accuracy_med)\n",
        "\n",
        "mae_med = mean_absolute_error(y_med, y_pred_med)\n",
        "print(\"Tiny Dataset Mean Absolute Error :\", mae_med)\n",
        "\n",
        "# --- Example Usage (Prediction) ---\n",
        "new_text = [\"This product is absolutely fantastic!\"]\n",
        "new_text_vectorized = embed(new_text)\n",
        "prediction = model.predict(new_text_vectorized)\n",
        "predicted_class = np.argmax(prediction[0])\n",
        "print(\"Predicted sentiment class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqe-6FWeOWu-",
        "outputId": "3ad2b452-e703-4561-a028-b33cec52ae00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ]
        }
      ]
    }
  ]
}